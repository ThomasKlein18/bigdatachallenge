{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5611 2433 5311 5051 1184 4555 3385 4117 4843 2904]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#np.random.seed(42)\n",
    "indices = np.random.randint(0, 6384, 10)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l [array([[3, 4, 5],\n",
      "       [5, 6, 7],\n",
      "       [6, 7, 8],\n",
      "       [1, 2, 3]])]\n"
     ]
    }
   ],
   "source": [
    "indices = [1,2]\n",
    "res = np.take(l, indices)\n",
    "l = np.delete(l, indices)\n",
    "\n",
    "#print(\"res\",res)\n",
    "print(\"l\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "fruits = ['banana', 'apple', 'cherry']\n",
    "sample = 'apple'\n",
    "\n",
    "indices = np.where(fruits == sample)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8020//11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8019"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11*729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "(15, 4)\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "(20, 4)\n"
     ]
    }
   ],
   "source": [
    "data = np.ones((15,4))\n",
    "print(data)\n",
    "print(data.shape)\n",
    "\n",
    "new = np.pad(data, [(0,5),(0,0)], 'constant', constant_values=0)\n",
    "\n",
    "print(new)\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10//6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(4, 3, 3)\n",
      "[[[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "c = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "d = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "print(a.shape)\n",
    "val = [a,b,c,d]\n",
    "\n",
    "res = np.stack(val)\n",
    "print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 2, 3]]), array([[4, 5, 6]]), array([[7, 8, 9]])]\n",
      "[array([[1, 2, 3]]), array([[4, 5, 6]]), array([[7, 8, 9]])]\n",
      "[array([[1, 2, 3]]), array([[4, 5, 6]]), array([[7, 8, 9]])]\n",
      "[array([[1, 2, 3]]), array([[4, 5, 6]]), array([[7, 8, 9]])]\n"
     ]
    }
   ],
   "source": [
    "for x in res:\n",
    "    sub = np.split(x,3)\n",
    "    print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: a\n",
      "l: adsf\n",
      "s: b\n",
      "l: bsdf\n",
      "s: c\n",
      "l: csdf\n"
     ]
    }
   ],
   "source": [
    "a = ['a','b','c']\n",
    "b = ['adsf','bsdf','csdf']\n",
    "\n",
    "for s,l in zip(a,b):\n",
    "    print(\"s:\",s)\n",
    "    print(\"l:\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([10,44,2]).argsort()) # argsort liefert die permutation der indices die das array aufsteigend sortiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56. 11. 34.]\n",
      " [12. 10.  8.]\n",
      " [ 6.  5.  4.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[3,4,0],\n",
    "              [1,2,6],\n",
    "              [6,5,7]])\n",
    "\n",
    "c = np.array([[11., 34., 56.],\n",
    "              [10.,  8., 12.],\n",
    "              [ 5.,  4.,  6.]])\n",
    "wasichwill = np.array([[56, 11, 34],\n",
    "                       [12, 10, 8],\n",
    "                       [6, 5, 4]])\n",
    "b = c[:,-c[1,:].argsort()]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'b' 'c' 'd' 'e' 'f']\n"
     ]
    }
   ],
   "source": [
    "one = ['a','b','c']\n",
    "two = ['d','e','f']\n",
    "\n",
    "print(np.concatenate((one, two)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"output.csv\", \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([123.4,454.3,123.334,234.455,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"fakefeatures.csv\").values\n",
    "print(np.mean(data[:,0:98],axis=0).shape)\n",
    "data[:,0:98] = (data[:,0:98]-np.mean(data[:,0:98],axis=0))/np.std(data[:,0:98],axis=0)\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv(\"normalizedfeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "[[ 1  2  3]\n",
      " [11  1  2]]\n",
      "b\n",
      "[[4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9],\n",
    "              [11,1,2]])\n",
    "print(a.shape)\n",
    "b = np.take(a,[1,2], axis=0)\n",
    "a=np.delete(a,[1,2], axis=0)\n",
    "\n",
    "print(a)\n",
    "print(\"b\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4  1  2 -2 -6  1  0  1  6 19 15]\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "a = np.array([3,4,7,5,9,3,3,4,3,5,9,24])\n",
    "res = ndimage.sobel(a, 0)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 350  700 1500]\n",
      " [ 100  560  400]\n",
      " [ 234  456  234]]\n",
      "[1 2 0]\n",
      "[[ 350  700 1500]\n",
      " [ 100  560  400]\n",
      " [ 234  456  234]]\n"
     ]
    }
   ],
   "source": [
    "results = np.array([[350, 700, 1500],[100, 560, 400],[234,456,234]])\n",
    "print(results)\n",
    "print((-results[1,:]).argsort())\n",
    "results = results[:,-results[1,:].argsort()]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with threaded feature extraction\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "import csv\n",
    "\n",
    "sensors = ['EMG1', 'EMG2', 'EMG3', 'EMG4', 'Microphone', 'ACC upper X', 'ACC upper Y','ACC upper Z', 'Goniometer X',\n",
    "          'ACC lower X', 'ACC lower Y', 'ACC lower Z', 'Goniometer Y', 'Gyro upper X', 'Gyro upper Y', 'Gyro upper Z',\n",
    "          'Gyro lower X', 'Gyro lower Y', 'Gyro lower Z']\n",
    "\n",
    "variance_sensors = ['EMG1', 'EMG2', 'EMG3', 'EMG4', 'Microphone']\n",
    "\n",
    "smooth_sensors = ['ACC upper X', 'ACC upper Y','ACC upper Z', 'Goniometer X','ACC lower X', 'ACC lower Y', \n",
    "                  'ACC lower Z', 'Goniometer Y', 'Gyro upper X', 'Gyro upper Y', 'Gyro upper Z', 'Gyro lower X', \n",
    "                  'Gyro lower Y', 'Gyro lower Z']\n",
    "\n",
    "def smooth(data, windowsize, std):\n",
    "    kernel = signal.gaussian(windowsize, std=std)\n",
    "    kernel /= np.sum(kernel)\n",
    "    return np.convolve(data, kernel, 'valid')\n",
    "\n",
    "def variance_filter(data, windowsize):\n",
    "    half = windowsize//2\n",
    "    res = np.zeros(data.shape[0]-windowsize)\n",
    "    for i in range(half,len(data)-half):\n",
    "        res[i-half] = np.std(data[i-half:i+half])\n",
    "    return res / np.max(res)\n",
    "\n",
    "def sample(data, num_samples):\n",
    "    samples = [int(sample) for sample in np.linspace(0, data.shape[0]-1, num_samples)]\n",
    "    return data[samples]\n",
    "    \n",
    "def smooth_extractor(data, num_samples):\n",
    "    \"\"\"\n",
    "    data = 1d-numpy array of length timestep:\n",
    "    \"\"\"\n",
    "    smoothed = smooth(data,200,50)\n",
    "    normalized = (smoothed-np.mean(smoothed))/np.max(smoothed)\n",
    "    return sample(normalized, num_samples)\n",
    "\n",
    "def variance_extractor(data, num_samples):\n",
    "    \"\"\"\n",
    "    data = 1d-numpy array of length timesteps\n",
    "    \"\"\"\n",
    "    var_data = smooth(variance_filter(data,windowsize=100),windowsize=100,std=25)\n",
    "    return sample(var_data, num_samples)\n",
    "\n",
    "def threaded_recurrent_feature_extractor(data, num_samples):\n",
    "    \"\"\"\n",
    "    data = 2d-numpy array of shape [timesteps, sensors]\n",
    "    \n",
    "    \"\"\"\n",
    "    pool = ThreadPool(4)\n",
    "    \n",
    "    variance_sequences = []\n",
    "    smooth_sequences = []\n",
    "    \n",
    "    for sensor in variance_sensors:\n",
    "        variance_sequences.append(data[:,sensors.index(sensor)])\n",
    "        \n",
    "    for sensor in smooth_sensors:\n",
    "        smooth_sequences.append(data[:,sensors.index(sensor)])\n",
    "        \n",
    "    var_results = pool.starmap(variance_extractor, zip(variance_sequences, itertools.repeat(num_samples)))\n",
    "    smo_results = pool.starmap(smooth_extractor, zip(smooth_sequences, itertools.repeat(num_samples)))\n",
    "        \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return var_results + smo_results\n",
    "\n",
    "def recurrent_feature_extractor(data, num_samples):\n",
    "    \"\"\"\n",
    "    data = 2d-numpy array of shape [timesteps, sensors]\n",
    "    \n",
    "    \"\"\"\n",
    "    features = []\n",
    "        \n",
    "    for sensor in variance_sensors:\n",
    "        features.append(variance_extractor(data[:,sensors.index(sensor)], num_samples))\n",
    "        \n",
    "    for sensor in smooth_sensors:\n",
    "        features.append(smooth_extractor(data[:,sensors.index(sensor)], num_samples))\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threaded result: 356.95526433794294\n",
      "Unthreaded result: 356.7150718709454\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "path = \"/Users/thomasklein/Projects/BremenBigDataChallenge2019/bbdc_2019_Bewegungsdaten/Subject02/Subject02_Aufnahme215.csv\"\n",
    "testdata = pd.read_csv(path).values\n",
    "\n",
    "res = threaded_recurrent_feature_extractor(testdata, 80)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "for i in range(1000):\n",
    "    res = threaded_recurrent_feature_extractor(testdata, 80)\n",
    "print(\"Threaded result:\",timeit.default_timer() - start_time)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "for i in range(1000):\n",
    "    res = threaded_recurrent_feature_extractor(testdata, 80)\n",
    "print(\"Unthreaded result:\",timeit.default_timer() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_model = tf.keras.models.load_model('/Users/thomasklein/Projects/BremenBigDataChallenge2019/bigdatachallenge/recurrent/model/readout_lstm.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.random.randint(0, 6384, 10)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6,  9, 12],\n",
       "       [16, 20, 24, 28],\n",
       "       [40, 15, 30, 35]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],\n",
    "            [4,5,6,7],\n",
    "            [8,3,6,7]])\n",
    "\n",
    "b = np.array([3,4,5])\n",
    "\n",
    "(a.T * b).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-801877c11bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m vals = tf.constant([[4.0, 5.4, 6.9, 7.0,],\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5421\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5422\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5423\u001b[0;31m         server_def=None)\n\u001b[0m\u001b[1;32m   5424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   5465\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5466\u001b[0m       raise ValueError(\n\u001b[0;32m-> 5467\u001b[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5468\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5469\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "vals = tf.constant([[4.0, 5.4, 6.9, 7.0,],\n",
    "                    [4.5, 1.2, 3.1, 7.9],\n",
    "                    [5.7, 3.1, 7.8, 8.7]], dtype=tf.float32) # shape (3,4)\n",
    "means = tf.constant([1,2,3,4], dtype=tf.float32)\n",
    "\n",
    "\n",
    "print(vals-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
